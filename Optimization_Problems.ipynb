{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1_225_gnL1-",
        "outputId": "de76fa21-f856-402d-83eb-65150f575f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "В точке x = 2:\n",
            "Значение функции f(x) = 3\n",
            "Значение производной f'(x) = 7\n"
          ]
        }
      ],
      "source": [
        "def f(x):\n",
        "  return 3*x**2-5*x+1\n",
        "\n",
        "def df(x):\n",
        "  return 6*x-5\n",
        "\n",
        "x = 2\n",
        "\n",
        "print(f\"В точке x = {x}:\")\n",
        "print(f\"Значение функции f(x) = {f(x)}\")\n",
        "print(f\"Значение производной f'(x) = {df(x)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x,y):\n",
        "  return x**2 + 4*y\n",
        "\n",
        "def df_x(x,y):\n",
        "  return 2*x\n",
        "\n",
        "def df_y(x,y):\n",
        "  return  4\n",
        "\n",
        "point = (1,-1)\n",
        "\n",
        "print(f\"Градиент в точке {point}: {df_x(point[0],point[1]),df_y(point[0],point[1])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJOLZKhQox5b",
        "outputId": "cd894d15-1dcc-4fd9-d3b6-2bd6783c66e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Градиент в точке (1, -1): (2, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dJ(thetta):\n",
        "  return 2*thetta-10\n",
        "\n",
        "eta = 0.1\n",
        "iterations = 20\n",
        "thetta = 0\n",
        "for i in range(iterations):\n",
        "  thetta = thetta - eta * dJ(thetta)\n",
        "\n",
        "thetta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkRnvKbrq-VU",
        "outputId": "8922f571-2581-46ab-8ba2-7dd06be884d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.942353924769658"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dJ(thetta):\n",
        "  return 2*thetta-10\n",
        "\n",
        "iterations = 20\n",
        "thetta = 0\n",
        "\n",
        "def thetta_new(eta,thetta):\n",
        "  for i in range(iterations):\n",
        "    thetta = thetta - eta * dJ(thetta)\n",
        "  return thetta\n",
        "\n",
        "print(thetta_new(0.01,thetta))\n",
        "print(thetta_new(0.1,thetta))\n",
        "print(thetta_new(1,thetta))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mio6byn8sG9q",
        "outputId": "fe346368-7cd5-4fc3-c8d3-e52db45ee8e7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6619601412245273\n",
            "4.942353924769658\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_2d(x, y, eta, iter):\n",
        "\n",
        "    for i in range(iter):\n",
        "        grad_x = 2 * x\n",
        "        grad_y = 2 * y\n",
        "\n",
        "        x = x - eta * grad_x\n",
        "        y = y - eta * grad_y\n",
        "\n",
        "    return x, y\n",
        "\n",
        "point = (3, -4)\n",
        "eta = 0.1\n",
        "iter = 20\n",
        "\n",
        "values = gradient_descent_2d(*point,eta,iter)\n",
        "loss = (values[0])**2 + (values[1])**2\n",
        "\n",
        "print(values)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722AFzgtug7d",
        "outputId": "25086e1a-6097-4d1b-f811-388ff00f015e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.03458764513820541, -0.04611686018427388)\n",
            "0.0033230699894622904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y = np.array([2, 4, 6])\n",
        "y_pred = np.array([2.5, 3.5, 5.0])\n",
        "\n",
        "mse = ((y-y_pred)**2).mean()\n",
        "print(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG1wXZdhxss0",
        "outputId": "0aa85df2-3506-4fbb-e601-c36eae688ea3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "theta = np.array([2.0, -0.5, 0.1])\n",
        "lam = 0.1\n",
        "\n",
        "l1_penalty = lam * np.sum(np.abs(theta))\n",
        "\n",
        "l2_penalty = lam * np.sum(theta ** 2)\n",
        "\n",
        "print(f\"L1 штраф: {l1_penalty}\")\n",
        "print(f\"L2 штраф: {l2_penalty}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjN1W8FB3z4F",
        "outputId": "a46f73e5-16b0-428c-e01b-fa01b1368097"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 штраф: 0.26\n",
            "L2 штраф: 0.426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return x**2 - 6*x + 8\n",
        "def df(x):\n",
        "  return 2*x - 6\n",
        "def d2f(x):\n",
        "  return 2\n",
        "\n",
        "iterations = 5\n",
        "def newtons_method(x, iterations):\n",
        "    for i in range(iterations):\n",
        "        grad = df(x)\n",
        "        hessian = d2f(x)\n",
        "        x = x - (grad / hessian)\n",
        "    return x\n",
        "\n",
        "final_x = newtons_method(10,5)\n",
        "final_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIrm-9lu4OC-",
        "outputId": "0df025d9-4be4-4d6d-a27a-6d45d344f7b0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegressionFromScratch:\n",
        "    def __init__(self, learning_rate=0.1, n_iterations=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        # Сигмоида превращает любое число в вероятность (от 0 до 1)\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def compute_loss(self, y_true, y_pred):\n",
        "        # Binary Cross-Entropy Loss\n",
        "        # Добавляем epsilon, чтобы не взять log(0)\n",
        "        epsilon = 1e-15\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Инициализация параметров\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Градиентный спуск\n",
        "        for i in range(self.n_iterations):\n",
        "            # 1. Forward pass (Линейная модель + Активация)\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_predicted = self.sigmoid(linear_model)\n",
        "\n",
        "            # 2. Backward pass (Вычисление градиентов)\n",
        "            # Производная dLoss/dw сводится к формуле: (1/N) * X.T * (y_pred - y)\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            # 3. Обновление весов\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "            # Вывод лосса каждые 100 итераций\n",
        "            if i % 100 == 0:\n",
        "                loss = self.compute_loss(y, y_predicted)\n",
        "                print(f\"Iter {i}: Loss {loss:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.sigmoid(linear_model)\n",
        "        # Если вероятность > 0.5, то класс 1, иначе 0\n",
        "        return [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "\n",
        "# --- Проверка работы ---\n",
        "# Данные (логическое ИЛИ)\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([0, 1, 1, 1]) # 0 только если (0,0)\n",
        "\n",
        "model = LogisticRegressionFromScratch(learning_rate=0.1, n_iterations=1000)\n",
        "model.fit(X, y)\n",
        "\n",
        "print(f\"\\nПредсказание для [0, 0]: {model.predict(np.array([[0,0]]))}\") # Ожидаем 0\n",
        "print(f\"Предсказание для [1, 0]: {model.predict(np.array([[1,0]]))}\") # Ожидаем 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX72TTUp40ST",
        "outputId": "a43c4424-2189-42f8-930f-70bcaa84af75"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0: Loss 0.6931\n",
            "Iter 100: Loss 0.3423\n",
            "Iter 200: Loss 0.2669\n",
            "Iter 300: Loss 0.2174\n",
            "Iter 400: Loss 0.1825\n",
            "Iter 500: Loss 0.1568\n",
            "Iter 600: Loss 0.1371\n",
            "Iter 700: Loss 0.1215\n",
            "Iter 800: Loss 0.1090\n",
            "Iter 900: Loss 0.0987\n",
            "\n",
            "Предсказание для [0, 0]: [0]\n",
            "Предсказание для [1, 0]: [1]\n"
          ]
        }
      ]
    }
  ]
}